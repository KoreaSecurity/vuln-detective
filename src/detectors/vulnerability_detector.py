"""Main vulnerability detection engine"""

import re
import json
from enum import Enum
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict

from ..models.base import BaseModel
from ..models.factory import ModelFactory, ModelType


class VulnerabilitySeverity(Enum):
    """Vulnerability severity levels"""
    CRITICAL = "Critical"
    HIGH = "High"
    MEDIUM = "Medium"
    LOW = "Low"
    INFO = "Info"


@dataclass
class Vulnerability:
    """Represents a detected vulnerability"""
    vuln_type: str
    cwe_id: str
    severity: VulnerabilitySeverity
    line_number: int
    description: str
    code_snippet: str
    exploitability: str
    recommendation: str
    confidence: float = 1.0
    metadata: Optional[Dict[str, Any]] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary"""
        result = asdict(self)
        result['severity'] = self.severity.value
        return result


class VulnerabilityDetector:
    """Main vulnerability detection engine using AI"""

    def __init__(self, model: Optional[BaseModel] = None):
        self.model = model or ModelFactory.create_default_model()
        self.fast_model = ModelFactory.create_fast_model()

        # Vulnerability patterns for initial screening
        self.patterns = {
            "buffer_overflow": [
                r"\bstrcpy\s*\(",
                r"\bsprintf\s*\(",
                r"\bgets\s*\(",
                r"\bstrcat\s*\(",
            ],
            "sql_injection": [
                r"execute\s*\(\s*['\"].*\+.*['\"]",
                r"query\s*\(\s*['\"].*\+.*['\"]",
                r"SELECT.*FROM.*WHERE.*\+",
            ],
            "command_injection": [
                r"\bsystem\s*\(",
                r"\bexec\s*\(",
                r"\bpopen\s*\(",
                r"\beval\s*\(",
            ],
            "xss": [
                r"innerHTML\s*=",
                r"document\.write\s*\(",
                r"\.html\s*\(",
            ],
        }

    async def detect(
        self,
        code: str,
        language: str,
        filename: Optional[str] = None,
    ) -> List[Vulnerability]:
        """Detect vulnerabilities in code"""

        # Step 1: Quick pattern-based screening
        suspicious_patterns = self._pattern_screening(code)

        # Step 2: AI-powered deep analysis
        if suspicious_patterns or len(code) < 10000:
            # Use chain-of-thought for detailed analysis
            vulnerabilities = await self._ai_detection(code, language, suspicious_patterns)
        else:
            # For large files, analyze in chunks
            vulnerabilities = await self._chunked_detection(code, language)

        # Step 3: Verification
        verified_vulns = await self._verify_vulnerabilities(code, vulnerabilities)

        # Step 4: Enrich with additional metadata
        for vuln in verified_vulns:
            vuln.metadata = vuln.metadata or {}
            vuln.metadata['filename'] = filename
            vuln.metadata['language'] = language

        return verified_vulns

    def _pattern_screening(self, code: str) -> Dict[str, List[int]]:
        """Quick pattern-based screening to identify suspicious code"""
        findings = {}

        for vuln_type, patterns in self.patterns.items():
            matches = []
            for pattern in patterns:
                for match in re.finditer(pattern, code, re.IGNORECASE):
                    # Find line number
                    line_num = code[:match.start()].count('\n') + 1
                    matches.append(line_num)

            if matches:
                findings[vuln_type] = matches

        return findings

    async def _ai_detection(
        self,
        code: str,
        language: str,
        suspicious_patterns: Dict[str, List[int]],
    ) -> List[Vulnerability]:
        """AI-powered vulnerability detection"""

        context = ""
        if suspicious_patterns:
            context = "\n\nNote: Pattern analysis found potential issues:\n"
            for vuln_type, lines in suspicious_patterns.items():
                context += f"- {vuln_type} at lines: {', '.join(map(str, lines))}\n"

        # Use structured response for easier parsing
        prompt = f"""Analyze this {language} code for security vulnerabilities.

{context}

Code:
```{language}
{code}
```

For each REAL vulnerability found (not theoretical or low-confidence issues), provide details in JSON format:

{{
  "vulnerabilities": [
    {{
      "type": "vulnerability type",
      "cwe_id": "CWE-XXX",
      "severity": "Critical|High|Medium|Low",
      "line": line_number,
      "description": "clear description",
      "code_snippet": "relevant code",
      "exploitability": "how to exploit",
      "recommendation": "how to fix",
      "confidence": 0.0-1.0
    }}
  ]
}}

Only include vulnerabilities you are confident about (confidence > 0.7).
"""

        response = await self.model.complete(
            prompt=prompt,
            system_prompt="You are a security expert. Be precise and avoid false positives.",
        )

        return self._parse_vulnerabilities(response.content, code)

    def _parse_vulnerabilities(
        self,
        response_text: str,
        code: str,
    ) -> List[Vulnerability]:
        """Parse vulnerabilities from AI response"""
        vulnerabilities = []

        try:
            # Try to extract JSON
            json_match = re.search(r'\{[\s\S]*"vulnerabilities"[\s\S]*\}', response_text)
            if json_match:
                data = json.loads(json_match.group(0))
                vuln_list = data.get("vulnerabilities", [])

                for vuln_data in vuln_list:
                    try:
                        severity = VulnerabilitySeverity[vuln_data.get("severity", "MEDIUM").upper()]
                    except KeyError:
                        severity = VulnerabilitySeverity.MEDIUM

                    vuln = Vulnerability(
                        vuln_type=vuln_data.get("type", "Unknown"),
                        cwe_id=vuln_data.get("cwe_id", "CWE-Unknown"),
                        severity=severity,
                        line_number=int(vuln_data.get("line", 0)),
                        description=vuln_data.get("description", ""),
                        code_snippet=vuln_data.get("code_snippet", ""),
                        exploitability=vuln_data.get("exploitability", ""),
                        recommendation=vuln_data.get("recommendation", ""),
                        confidence=float(vuln_data.get("confidence", 0.8)),
                    )
                    vulnerabilities.append(vuln)

        except (json.JSONDecodeError, KeyError, ValueError) as e:
            # Fallback: parse text format
            vulnerabilities = self._parse_text_vulnerabilities(response_text, code)

        return vulnerabilities

    def _parse_text_vulnerabilities(
        self,
        text: str,
        code: str,
    ) -> List[Vulnerability]:
        """Fallback parser for non-JSON responses"""
        vulnerabilities = []

        # Simple heuristic parsing
        lines = text.split('\n')
        current_vuln = {}

        for line in lines:
            line = line.strip()

            if 'type:' in line.lower():
                if current_vuln:
                    vulnerabilities.append(self._create_vulnerability(current_vuln))
                current_vuln = {'type': line.split(':', 1)[1].strip()}

            elif 'cwe' in line.lower():
                current_vuln['cwe'] = line.split(':', 1)[1].strip()

            elif 'severity:' in line.lower():
                current_vuln['severity'] = line.split(':', 1)[1].strip()

            elif 'line' in line.lower() and ':' in line:
                try:
                    num = re.search(r'\d+', line)
                    if num:
                        current_vuln['line'] = int(num.group())
                except ValueError:
                    pass

        if current_vuln:
            vulnerabilities.append(self._create_vulnerability(current_vuln))

        return vulnerabilities

    def _create_vulnerability(self, data: Dict[str, Any]) -> Vulnerability:
        """Create Vulnerability object from parsed data"""
        try:
            severity = VulnerabilitySeverity[data.get('severity', 'MEDIUM').upper()]
        except KeyError:
            severity = VulnerabilitySeverity.MEDIUM

        return Vulnerability(
            vuln_type=data.get('type', 'Unknown'),
            cwe_id=data.get('cwe', 'CWE-Unknown'),
            severity=severity,
            line_number=data.get('line', 0),
            description=data.get('description', ''),
            code_snippet=data.get('code_snippet', ''),
            exploitability=data.get('exploitability', ''),
            recommendation=data.get('recommendation', ''),
            confidence=0.7,
        )

    async def _chunked_detection(
        self,
        code: str,
        language: str,
    ) -> List[Vulnerability]:
        """Detect vulnerabilities in large files by analyzing chunks"""
        # Split code into functions/classes
        chunks = self._split_code(code)
        all_vulns = []

        for chunk in chunks:
            vulns = await self._ai_detection(chunk['code'], language, {})
            # Adjust line numbers based on chunk offset
            for vuln in vulns:
                vuln.line_number += chunk['offset']
            all_vulns.extend(vulns)

        return all_vulns

    def _split_code(self, code: str) -> List[Dict[str, Any]]:
        """Split code into analyzable chunks"""
        # Simple function-based splitting
        chunks = []
        lines = code.split('\n')

        current_chunk = []
        current_offset = 0
        in_function = False

        for i, line in enumerate(lines):
            # Simple heuristic for function detection
            if re.match(r'^\s*(def|function|func|public|private|protected)\s+\w+', line):
                if current_chunk:
                    chunks.append({
                        'code': '\n'.join(current_chunk),
                        'offset': current_offset
                    })
                current_chunk = [line]
                current_offset = i
                in_function = True
            else:
                current_chunk.append(line)

                # End of function (basic heuristic)
                if in_function and len(current_chunk) > 50:
                    chunks.append({
                        'code': '\n'.join(current_chunk),
                        'offset': current_offset
                    })
                    current_chunk = []
                    in_function = False

        if current_chunk:
            chunks.append({
                'code': '\n'.join(current_chunk),
                'offset': current_offset
            })

        return chunks or [{'code': code, 'offset': 0}]

    async def _verify_vulnerabilities(
        self,
        code: str,
        vulnerabilities: List[Vulnerability],
    ) -> List[Vulnerability]:
        """Verify detected vulnerabilities to reduce false positives"""
        verified = []

        for vuln in vulnerabilities:
            # Only verify medium confidence vulnerabilities
            if vuln.confidence >= 0.8:
                verified.append(vuln)
            elif vuln.confidence >= 0.6:
                # Use fast model for verification
                try:
                    is_valid = await self._verify_single(code, vuln)
                    if is_valid:
                        verified.append(vuln)
                except Exception:
                    # On error, include with reduced confidence
                    vuln.confidence *= 0.8
                    verified.append(vuln)

        return verified

    async def _verify_single(self, code: str, vuln: Vulnerability) -> bool:
        """Verify a single vulnerability"""
        # Extract context around the vulnerability
        lines = code.split('\n')
        start = max(0, vuln.line_number - 5)
        end = min(len(lines), vuln.line_number + 5)
        context = '\n'.join(lines[start:end])

        prompt = f"""Is this a real vulnerability or a false positive?

Suspected issue:
Type: {vuln.vuln_type}
Line: {vuln.line_number}

Code context:
```
{context}
```

Answer: TRUE_POSITIVE or FALSE_POSITIVE
Then explain why in one sentence.
"""

        response = await self.fast_model.complete(prompt)
        return "TRUE_POSITIVE" in response.content.upper()
